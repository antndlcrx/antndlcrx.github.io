---
title: Programme 2024
author: maksim
date: 2025-07-05
categories: [Programme]
tags: [programme, oxllms 2025]
pin: false

---

## Program Overview

The Oxford LLMs Program is a five-day workshop that combines lectures, coding sessions, collaborative projects, and guest talks. Participants learn how large language models work, how to adapt them to new domains, how to evaluate them, and how to deploy them safely and fairly.

## Daily Structure

Each day follows the same four-part structure:

1. **Lecture (90 min):** Core concepts and methods  
2. **Coding Session (90 min):** Hands-on exercises using Python and Jupyter notebooks  
3. **Collaborative Research (120 min):** Small teams work on a real research question, aiming for a peer-review write-up  
4. **Guest Talk (60 min):** A social scientist presents their LLM research and answers questions  

## Main Topics

### 1) Foundations of LLMs  
In this module, participants will explore **training objectives for language models**, learning how predictive tasks shape internal representations. They will dive into **transformer architecture and in-context learning**, examining how self-attention enables models to process and generate coherent text. Finally, the session covers **model reasoning and emergent capabilities**, demonstrating how large models can perform complex tasks without explicit fine-tuning.

### 2) Adapting LLMs to Specific Domains  
This part focuses on **post-training methods**, such as continued pre-training and fine-tuning, to specialize models for target tasks. Participants will discuss **data selection and annotation strategies**, understanding how dataset quality impacts performance. The module concludes with an overview of **tooling for rapid domain adaptation**, introducing libraries and workflows for efficient model updates.

### 3) Evaluating Language Models  
Here, we examine **classic tests**, including Turing-style probes, to assess basic language understanding. Next, we cover **benchmarks for generalization and robustness**, comparing standard datasets and stress-test protocols. The session ends with **metrics for real-world performance and reliability**, teaching how to measure model behavior on downstream tasks and in production scenarios.

### 4) Safety and Fairness in LLMs  
Participants will learn **bias detection and mitigation techniques**, from dataset debiasing to counterfactual augmentation. We then explore **alignment strategies**, such as instruction tuning and RLHF, that steer models toward desired behaviors. The module wraps up with a discussion of **ethical and societal considerations**, highlighting best practices for responsible deployment.

## What You Will Gain

- A clear understanding of transformer-based LLMs  
- Practical experience with state-of-the-art tools and libraries  
- Hands-on research skills in computational social science  
- Insight into current LLM applications in political science and related fields  

## Preparation

Participants should be ready to code in Python and have familiarity with basic NLP concepts. All materials, datasets, and example code will be provided ahead of time.

> For anyone who needs a refresher on the basics, we also provide a short [self-study pack of readings and coding exercises](https://llmsforsocialscience.net/preliminaries/) to complete before the workshop. 
{: .prompt-info }
