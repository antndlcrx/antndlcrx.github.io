---
title: Oxford LLMs 2023 Materials
author: maksim
date: 2024-05-23
categories: [Programme, Materials]
tags: [programme, fundamentals, alignment, interpretability, peft, prompts, llama2]
pin: true
---

Explore our comprehensive 2023 lecture and workshop series, featuring materials created by Elena Voita and Ilya Boytsov. Delve into the evolutionary journey of NLP, understand biases and interpretability in LLMs, and learn about alignment from lecture slides and in our upcoming(!) lecture videos. Our workshops cover essential topics such as setting up Google Colab, using Huggingface transformers, topic modeling with BERTopic, fine-tuning pretrained models, parameter-efficient fine-tuning, transformer interpretability, classic NLP with Spacy, prompts and instructions with Llama 2, and detoxifying summarization models with reinforcement learning. Stay tuned for the release of the video recordings!

# 2023 Lectures

The following lecture materials were and created by [Elena Voita](https://lena-voita.github.io/).
- [The Evolutionary Journey of NLP](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/lectures/day_1/The%20Evolutionary%20Journey%20in%20NLP.pdf) from rule-based systems to modern Transformers-based models, which are the core technology underpinning LLMs. Video coming soon! 
- [Bias in LLMs and a (bit of) Interpretability](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/lectures/day_2/Bias%20in%20LLMs%20and%20interpretability.pdf). Video coming soon!
- [LLMs and Alignment](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/lectures/day_3/Prompt%20engineering%2C%20RHLF%2C%20ChatGPT.pdf)
Video coming soon!

# 2023 Workshops
The following workshop materials were designed and implemented by [Ilya Boytsov](https://www.linkedin.com/in/ieboytsov/).
We will upload the workshop recordings soon!
- [Google Colab environment setup, general intro](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_1/0_Env%20setup%20and%20intro.ipynb)
- [Introduction to Huggingface transformers library](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_1/1_Intro%20to%20transformers.ipynb)
- [Topic modelling with Transformers using BERTopic library](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_1/2_Topic%20modelling%20with%20transformers.ipynb)
- [A guide how to fine-tune pretrained model for a classification task](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_1/3_Fine%20tune%20pretrained%20model.ipynb)
- [Parameter Efficient Fine Tuning (PEFT)](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_2/4_Parameter%20efficient%20fine%20tuning.ipynb)
- [Transformers interpretability, Attention visualisation, and saliancy methods (e.g. Integrated gradients)](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_2/5_Transformers%20interpretability.ipynb)
- [Model analys with classic NLP using Spacy](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_2/6_Sentiment%20analysis%20with%20classic%20NLP.ipynb)
- [Prompts and instructions with Llama 2](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_3/7_Prompts%20and%20instructions%20with%20Llama%202.ipynb)
- [Detoxifying summarisation model with Reinforcement Learning from Human Feedback (RLHF)](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_3/8_LLMs%20alignment%20with%20RLHF.ipynb)
